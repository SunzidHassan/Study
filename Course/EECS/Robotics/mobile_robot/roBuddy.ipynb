{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf052522",
   "metadata": {},
   "source": [
    "## Environment\n",
    "* Install Anaconda (install > nano ~/.bashrc > ~/anaconda3/bin/conda init > source ~/.bashrc)\n",
    "* Create Conda environment `conda create --name <your_environment_name> python=3.11`\n",
    "* Install CUDA toolkit\n",
    "* Install PyTorch\n",
    "* Install HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568c8cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  9 21:46:24 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2060        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P8              1W /   90W |       9MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3088      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA version\n",
    "!nvidia-smi\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c961416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/update required packages\n",
    "%pip install --quiet pvporcupine sounddevice soundfile librosa pyyaml matplotlib scipy transformers --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22690519",
   "metadata": {},
   "source": [
    "## Wake word detection using Porcupine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "CONFIG_PATH = Path.home() / \"Study\" / \"Course\" / \"EECS\" / \"Robotics\" / \"mobile_robot\" / \"config.yaml\"\n",
    "\n",
    "def load_config(file_path: Path = CONFIG_PATH) -> str:\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Config file not found at {file_path}\")\n",
    "    cfg = yaml.safe_load(file_path.read_text())\n",
    "    if \"PORCUPINE_KEY\" not in cfg:\n",
    "        raise KeyError(\"Missing 'PORCUPINE_KEY' in config\")\n",
    "    return cfg[\"PORCUPINE_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvporcupine\n",
    "porcupine = pvporcupine.create(access_key=load_config(), keywords=[\"jarvis\"])\n",
    "print(\"Porcupine frame_length:\", porcupine.frame_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e22447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "sd.query_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acef8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs, duration = 16000, 5\n",
    "print(\"Recording...\")\n",
    "rec = sd.rec(int(fs*duration), samplerate=fs, channels=1, dtype='int16')\n",
    "sd.wait()\n",
    "write(\"output.wav\", fs, rec)\n",
    "print(\"Saved output.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfae3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, soundfile as sf, librosa\n",
    "\n",
    "data, sr = sf.read(\"output.wav\")\n",
    "if data.ndim > 1:\n",
    "    data = data[:,0]\n",
    "if sr != 16000:\n",
    "    data = librosa.resample(data, sr, 16000)\n",
    "    sr = 16000\n",
    "if data.dtype != np.int16:\n",
    "    data = (data * 32767).astype(np.int16)\n",
    "\n",
    "for i in range(0, len(data) - porcupine.frame_length + 1, porcupine.frame_length):\n",
    "    if porcupine.process(data[i:i+porcupine.frame_length]) >= 0:\n",
    "        print(\"Detected at sample\", i)\n",
    "        break\n",
    "porcupine.delete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcfa04",
   "metadata": {},
   "source": [
    "## Speech-to-text: Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cea793",
   "metadata": {},
   "source": [
    "## Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15483e8f",
   "metadata": {},
   "source": [
    "## Text-to-speech: eSpeak NG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b270f",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8d053",
   "metadata": {},
   "source": [
    "## Qwen 2 Audio-7B Multimodal Audio Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e5509a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Qwen2AudioForConditionalGeneration, AutoProcessor\n\u001b[32m      6\u001b[39m processor = AutoProcessor.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen2-Audio-7B-Instruct\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mQwen2AudioForConditionalGeneration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQwen/Qwen2-Audio-7B-Instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/RoBuddy/lib/python3.13/site-packages/transformers/modeling_utils.py:313\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    311\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    315\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/RoBuddy/lib/python3.13/site-packages/transformers/modeling_utils.py:4392\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4390\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4391\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m4392\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4393\u001b[39m             (\n\u001b[32m   4394\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4395\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mrequires `accelerate`. You can install it with `pip install accelerate`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4396\u001b[39m             )\n\u001b[32m   4397\u001b[39m         )\n\u001b[32m   4399\u001b[39m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[32m   4400\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[31mValueError\u001b[39m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import librosa\n",
    "from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "model = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conversation1 = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/glass-breaking-151256.mp3\"},\n",
    "        {\"type\": \"text\", \"text\": \"What's that sound?\"},\n",
    "    ]},\n",
    "    {\"role\": \"assistant\", \"content\": \"It is the sound of glass shattering.\"},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/f2641_0_throatclearing.wav\"},\n",
    "        {\"type\": \"text\", \"text\": \"What can you hear?\"},\n",
    "    ]}\n",
    "]\n",
    "\n",
    "conversation2 = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/1272-128104-0000.flac\"},\n",
    "        {\"type\": \"text\", \"text\": \"What does the person say?\"},\n",
    "    ]},\n",
    "]\n",
    "\n",
    "conversations = [conversation1, conversation2]\n",
    "\n",
    "text = [processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False) for conversation in conversations]\n",
    "\n",
    "audios = []\n",
    "for conversation in conversations:\n",
    "    for message in conversation:\n",
    "        if isinstance(message[\"content\"], list):\n",
    "            for ele in message[\"content\"]:\n",
    "                if ele[\"type\"] == \"audio\":\n",
    "                    audios.append(\n",
    "                        librosa.load(\n",
    "                            BytesIO(urlopen(ele['audio_url']).read()), \n",
    "                            sr=processor.feature_extractor.sampling_rate)[0]\n",
    "                    )\n",
    "\n",
    "inputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True)\n",
    "inputs['input_ids'] = inputs['input_ids'].to(\"cuda\")\n",
    "inputs.input_ids = inputs.input_ids.to(\"cuda\")\n",
    "\n",
    "generate_ids = model.generate(**inputs, max_length=256)\n",
    "generate_ids = generate_ids[:, inputs.input_ids.size(1):]\n",
    "\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoBuddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
