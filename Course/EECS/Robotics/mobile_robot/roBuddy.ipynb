{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a606bdcb",
   "metadata": {},
   "source": [
    "## Wake-word detection & Qwen 2 Audio-7B demo\n",
    "**Sections:**\n",
    "1. Wake-word detection with Porcupine\n",
    "2. Multimodal audio understanding with Qwen 2 Audio-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41716cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/update required packages\n",
    "%pip install --quiet pvporcupine sounddevice soundfile librosa pyyaml matplotlib scipy transformers --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "CONFIG_PATH = Path.home() / \"Study\" / \"Course\" / \"EECS\" / \"Robotics\" / \"mobile_robot\" / \"config.yaml\"\n",
    "\n",
    "def load_config(file_path: Path = CONFIG_PATH) -> str:\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Config file not found at {file_path}\")\n",
    "    cfg = yaml.safe_load(file_path.read_text())\n",
    "    if \"PORCUPINE_KEY\" not in cfg:\n",
    "        raise KeyError(\"Missing 'PORCUPINE_KEY' in config\")\n",
    "    return cfg[\"PORCUPINE_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvporcupine\n",
    "porcupine = pvporcupine.create(access_key=load_config(), keywords=[\"jarvis\"])\n",
    "print(\"Porcupine frame_length:\", porcupine.frame_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e22447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "sd.query_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acef8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs, duration = 16000, 5\n",
    "print(\"Recording...\")\n",
    "rec = sd.rec(int(fs*duration), samplerate=fs, channels=1, dtype='int16')\n",
    "sd.wait()\n",
    "write(\"output.wav\", fs, rec)\n",
    "print(\"Saved output.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfae3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, soundfile as sf, librosa\n",
    "\n",
    "data, sr = sf.read(\"output.wav\")\n",
    "if data.ndim > 1:\n",
    "    data = data[:,0]\n",
    "if sr != 16000:\n",
    "    data = librosa.resample(data, sr, 16000)\n",
    "    sr = 16000\n",
    "if data.dtype != np.int16:\n",
    "    data = (data * 32767).astype(np.int16)\n",
    "\n",
    "for i in range(0, len(data) - porcupine.frame_length + 1, porcupine.frame_length):\n",
    "    if porcupine.process(data[i:i+porcupine.frame_length]) >= 0:\n",
    "        print(\"Detected at sample\", i)\n",
    "        break\n",
    "porcupine.delete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8d053",
   "metadata": {},
   "source": [
    "## Qwen 2 Audio-7B Multimodal Audio Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "import shutil, os, warnings, librosa, torch\n",
    "from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n",
    "\n",
    "# Check free disk space\n",
    "cache_dir = os.getenv(\"HF_HOME\", os.path.expanduser(\"~/.cache/huggingface/hub\"))\n",
    "free_mb = shutil.disk_usage(cache_dir).free // (1024*1024)\n",
    "if free_mb < 8000:\n",
    "    warnings.warn(f\"Low disk space: {free_mb}MB free, needs ~8000MB\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "model = Qwen2AudioForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\", torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "# Prepare sample conversations\n",
    "convo1 = [\n",
    "    {\"role\":\"user\",\"content\":[{\"type\":\"audio\",\"audio_url\":\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/glass-breaking-151256.mp3\"},{\"type\":\"text\",\"text\":\"What's that sound?\"}]},\n",
    "    {\"role\":\"assistant\",\"content\":\"It is the sound of glass shattering.\"},\n",
    "    {\"role\":\"user\",\"content\":[{\"type\":\"audio\",\"audio_url\":\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/f2641_0_throatclearing.wav\"},{\"type\":\"text\",\"text\":\"What can you hear?\"}]}\n",
    "]\n",
    "convo2 = [\n",
    "    {\"role\":\"user\",\"content\":[{\"type\":\"audio\",\"audio_url\":\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/1272-128104-0000.flac\"},{\"type\":\"text\",\"text\":\"What does the person say?\"}]}\n",
    "]\n",
    "conversations = [convo1, convo2]\n",
    "\n",
    "# Build prompts and load audio\n",
    "texts = [processor.apply_chat_template(c, add_generation_prompt=True, tokenize=False) for c in conversations]\n",
    "audios = []\n",
    "for c in conversations:\n",
    "    for msg in c:\n",
    "        for elem in msg.get(\"content\", []):\n",
    "            if elem[\"type\"] == \"audio\":\n",
    "                y, _ = librosa.load(\n",
    "                    BytesIO(urlopen(elem[\"audio_url\"]).read()),\n",
    "                    sr=processor.feature_extractor.sampling_rate\n",
    "                )\n",
    "                audios.append(y)\n",
    "\n",
    "# Tokenize + move to GPU\n",
    "inputs = processor(text=texts, audios=audios, return_tensors=\"pt\", padding=True)\n",
    "inputs = {k:(v.to(model.device) if torch.is_tensor(v) else v) for k,v in inputs.items()}\n",
    "\n",
    "# Generate and print responses\n",
    "gen = model.generate(**inputs, max_length=256)\n",
    "gen = gen[:, inputs['input_ids'].size(1):]\n",
    "out = processor.batch_decode(gen, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "for i, resp in enumerate(out,1):\n",
    "    print(f\"Conversation {i}: {resp}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
