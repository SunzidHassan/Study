{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch RL Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to TorchRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunzid/anaconda3/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=9298) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensordict-nightly\n",
      "  Downloading tensordict_nightly-2024.9.30-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "INFO: pip is looking at multiple versions of tensordict-nightly to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tensordict_nightly-2024.9.29-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.28-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.27-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.26-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.25-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.24-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.23-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "INFO: pip is still looking at multiple versions of tensordict-nightly to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tensordict_nightly-2024.9.22-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.21-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.20-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.19-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.18-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading tensordict_nightly-2024.9.16-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.15-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.14-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.13-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.12-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.11-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.10-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.9-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.8-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.7-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.6-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.5-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.4-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.3-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.2-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.9.1-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.31-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.30-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.29-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.28-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.27-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.26-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.25-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.24-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.23-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.22-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.21-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.20-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.19-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.18-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.17-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.16-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.15-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.14-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.13-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.12-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.11-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.10-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.9-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.8-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.7-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.6-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.5-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.4-cp312-cp312-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "  Downloading tensordict_nightly-2024.8.3-cp312-cp312-manylinux1_x86_64.whl.metadata (22 kB)\n",
      "  Downloading tensordict_nightly-2024.8.2-cp312-cp312-manylinux1_x86_64.whl.metadata (22 kB)\n",
      "  Downloading tensordict_nightly-2024.8.1-cp312-cp312-manylinux1_x86_64.whl.metadata (22 kB)\n",
      "  Downloading tensordict_nightly-2024.7.3-cp312-cp312-manylinux1_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: torch>=2.4.0.dev in /home/sunzid/anaconda3/lib/python3.12/site-packages (from tensordict-nightly) (2.4.1+cu124)\n",
      "Requirement already satisfied: numpy in /home/sunzid/anaconda3/lib/python3.12/site-packages (from tensordict-nightly) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle in /home/sunzid/anaconda3/lib/python3.12/site-packages (from tensordict-nightly) (2.2.1)\n",
      "Requirement already satisfied: orjson in /home/sunzid/anaconda3/lib/python3.12/site-packages (from tensordict-nightly) (3.10.7)\n",
      "Requirement already satisfied: filelock in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (1.12)\n",
      "Requirement already satisfied: networkx in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (69.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->tensordict-nightly) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.4.0.dev->tensordict-nightly) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2.4.0.dev->tensordict-nightly) (1.3.0)\n",
      "Downloading tensordict_nightly-2024.7.3-cp312-cp312-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensordict-nightly\n",
      "Successfully installed tensordict-nightly-2024.7.3\n",
      "Collecting torchrl-nightly\n",
      "  Downloading torchrl_nightly-2024.9.30-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "INFO: pip is looking at multiple versions of torchrl-nightly to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchrl_nightly-2024.9.29-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.28-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.27-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.26-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.25-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.24-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.23-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "INFO: pip is still looking at multiple versions of torchrl-nightly to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchrl_nightly-2024.9.22-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.21-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.20-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.19-cp312-cp312-manylinux1_x86_64.whl.metadata (39 kB)\n",
      "  Downloading torchrl_nightly-2024.9.16-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading torchrl_nightly-2024.9.15-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.14-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.13-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.12-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.11-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.10-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.9-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.8-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.7-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.6-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.5-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.4-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.3-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.2-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.9.1-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.31-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.30-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.29-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.28-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.27-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.26-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.25-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.24-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.23-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.22-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.21-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.20-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.19-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.18-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.17-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.16-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.15-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.14-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.13-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.12-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.11-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.10-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.9-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.8-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.7-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.6-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.5-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.4-cp312-cp312-manylinux1_x86_64.whl.metadata (34 kB)\n",
      "  Downloading torchrl_nightly-2024.8.3-cp312-cp312-manylinux1_x86_64.whl.metadata (33 kB)\n",
      "  Downloading torchrl_nightly-2024.8.2-cp312-cp312-manylinux1_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: torch>=2.4.0.dev in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torchrl-nightly) (2.4.1+cu124)\n",
      "Requirement already satisfied: numpy in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torchrl-nightly) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torchrl-nightly) (23.2)\n",
      "Requirement already satisfied: cloudpickle in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torchrl-nightly) (2.2.1)\n",
      "Requirement already satisfied: tensordict-nightly in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torchrl-nightly) (2024.7.3)\n",
      "Requirement already satisfied: filelock in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (1.12)\n",
      "Requirement already satisfied: networkx in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (69.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0.dev->torchrl-nightly) (3.0.0)\n",
      "Requirement already satisfied: orjson in /home/sunzid/anaconda3/lib/python3.12/site-packages (from tensordict-nightly->torchrl-nightly) (3.10.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.4.0.dev->torchrl-nightly) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from sympy->torch>=2.4.0.dev->torchrl-nightly) (1.3.0)\n",
      "Downloading torchrl_nightly-2024.8.2-cp312-cp312-manylinux1_x86_64.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: torchrl-nightly\n",
      "Successfully installed torchrl-nightly-2024.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensordict-nightly\n",
    "!pip install torchrl-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/sunzid/anaconda3/lib/python3.12/site-packages (from gymnasium) (4.11.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "\n",
    "torch.zeros(batch_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        key 1: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        key 2: Tensor(shape=torch.Size([5, 5, 6]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([5]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "tensordict = TensorDict(\n",
    "    source={\n",
    "        \"key 1\": torch.zeros(batch_size, 3),\n",
    "        \"key 2\": torch.zeros(batch_size, 5, 6, dtype=torch.bool),\n",
    "    },\n",
    "    batch_size=[batch_size]\n",
    ")\n",
    "\n",
    "print(tensordict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        key 1: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        key 2: Tensor(shape=torch.Size([5, 6]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False) \n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tensordict[2],'\\n')\n",
    "print(tensordict[\"key 1\"] is tensordict.get(\"key 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking multiple TensorDicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict1 = TensorDict(\n",
    "    source={\n",
    "        \"key 1\": torch.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments, TED and transform\n",
    "The standard RL training loop: train a model/policy to accomplish a task in an environment (e.g., a simulator).\n",
    "\n",
    ":mod:`~torchrl.envs` environment wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `env.reset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "reset = env.reset()\n",
    "print(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6809,  0.7323, -0.0661])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset[\"observation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a random action in the td."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "reset_with_action = env.rand_action(reset)\n",
    "print(reset_with_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6137])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_with_action[\"action\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `env.step()`\n",
    "Passing the td with initial env variable values and a random action to env.step().\n",
    "\n",
    "This returns TED - TorchRL Episode Data format - ubiquitous way of representing data in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "stepped_data = env.step(reset_with_action)\n",
    "print(stepped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`step_mdp`: to bring the \"next\" entry at root to perform the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import step_mdp\n",
    "\n",
    "data = step_mdp(stepped_data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `rollout()`\n",
    "Combination of three steps:\n",
    "- computing an action\n",
    "- taking a step\n",
    "- moving in the MDP\n",
    "\n",
    "Without a policy, it'll execute random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(max_steps=10)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "\n",
      "tensor([[-0.2421],\n",
      "        [ 0.6406],\n",
      "        [ 0.6442],\n",
      "        [ 0.2375],\n",
      "        [ 0.6837],\n",
      "        [-0.7404],\n",
      "        [-1.5189],\n",
      "        [-0.7908],\n",
      "        [ 0.2366],\n",
      "        [ 1.8354]])\n",
      "\n",
      "tensor([0.2375])\n"
     ]
    }
   ],
   "source": [
    "# spatial indexing\n",
    "print(rollout[3])\n",
    "print()\n",
    "\n",
    "# indexing by key\n",
    "print(rollout[\"action\"])\n",
    "print()\n",
    "\n",
    "# indexing by key and step\n",
    "print(rollout['action'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TransformedEnv`\n",
    "Complete list of transforms [here](https://pytorch.org/rl/stable/reference/envs.html#id2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import StepCounter, TransformedEnv\n",
    "\n",
    "transformed_env = TransformedEnv(env, StepCounter(max_steps=10))\n",
    "rollout = transformed_env.rollout(max_steps=100)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  tensor([[ 1.2521],\n",
      "        [ 0.3543],\n",
      "        [-1.4463],\n",
      "        [ 1.6247],\n",
      "        [-0.0473],\n",
      "        [-1.5524],\n",
      "        [-0.2393],\n",
      "        [ 0.3432],\n",
      "        [-0.4568],\n",
      "        [ 0.1557]]) \n",
      "\n",
      "done:  tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]]) \n",
      "\n",
      "observation:  tensor([[-0.8678,  0.4969, -0.0552],\n",
      "        [-0.8801,  0.4748,  0.5053],\n",
      "        [-0.9009,  0.4341,  0.9146],\n",
      "        [-0.9219,  0.3875,  1.0232],\n",
      "        [-0.9492,  0.3146,  1.5575],\n",
      "        [-0.9735,  0.2287,  1.7863],\n",
      "        [-0.9896,  0.1440,  1.7250],\n",
      "        [-0.9985,  0.0546,  1.7970],\n",
      "        [-0.9992, -0.0399,  1.8894],\n",
      "        [-0.9916, -0.1291,  1.7910]]) \n",
      "\n",
      "observation:  tensor([[[-0.8678,  0.4969, -0.0552],\n",
      "         [-0.8801,  0.4748,  0.5053]],\n",
      "\n",
      "        [[-0.8801,  0.4748,  0.5053],\n",
      "         [-0.9009,  0.4341,  0.9146]],\n",
      "\n",
      "        [[-0.9009,  0.4341,  0.9146],\n",
      "         [-0.9219,  0.3875,  1.0232]],\n",
      "\n",
      "        [[-0.9219,  0.3875,  1.0232],\n",
      "         [-0.9492,  0.3146,  1.5575]],\n",
      "\n",
      "        [[-0.9492,  0.3146,  1.5575],\n",
      "         [-0.9735,  0.2287,  1.7863]],\n",
      "\n",
      "        [[-0.9735,  0.2287,  1.7863],\n",
      "         [-0.9896,  0.1440,  1.7250]],\n",
      "\n",
      "        [[-0.9896,  0.1440,  1.7250],\n",
      "         [-0.9985,  0.0546,  1.7970]],\n",
      "\n",
      "        [[-0.9985,  0.0546,  1.7970],\n",
      "         [-0.9992, -0.0399,  1.8894]],\n",
      "\n",
      "        [[-0.9992, -0.0399,  1.8894],\n",
      "         [-0.9916, -0.1291,  1.7910]],\n",
      "\n",
      "        [[-0.9916, -0.1291,  1.7910],\n",
      "         [-0.9769, -0.2136,  1.7176]]]) \n",
      "\n",
      "step:  tensor([[[ 0],\n",
      "         [ 1]],\n",
      "\n",
      "        [[ 1],\n",
      "         [ 2]],\n",
      "\n",
      "        [[ 2],\n",
      "         [ 3]],\n",
      "\n",
      "        [[ 3],\n",
      "         [ 4]],\n",
      "\n",
      "        [[ 4],\n",
      "         [ 5]],\n",
      "\n",
      "        [[ 5],\n",
      "         [ 6]],\n",
      "\n",
      "        [[ 6],\n",
      "         [ 7]],\n",
      "\n",
      "        [[ 7],\n",
      "         [ 8]],\n",
      "\n",
      "        [[ 8],\n",
      "         [ 9]],\n",
      "\n",
      "        [[ 9],\n",
      "         [10]]]) \n",
      "\n",
      "terminated:  tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]]) \n",
      "\n",
      "truncated:  tensor([[[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [False]],\n",
      "\n",
      "        [[False],\n",
      "         [ True]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print('action: ', rollout[\"action\"],'\\n')\n",
    "print('done: ', rollout['done'],'\\n')\n",
    "print('observation: ', rollout['observation'],'\\n')\n",
    "print('observation: ', torch.stack([rollout[\"observation\"], rollout[\"next\",\"observation\"]],1),'\\n')\n",
    "# print('step: ', rollout['step_count'],'\\n')\n",
    "print('step: ', torch.stack([rollout[\"step_count\"], rollout[\"next\",\"step_count\"]],1),'\\n')\n",
    "print('terminated: ', rollout['terminated'],'\\n')\n",
    "# print('truncated: ', rollout['truncated'],'\\n')\n",
    "print('truncated: ', torch.stack([rollout[\"truncated\"], rollout[\"next\",\"truncated\"]],1),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TensorDictModules`: Policy construction\n",
    "Similar to how environments interact with instances of TensorDict, modules used to represent policies and vlaue functions also do the same. \n",
    "Code idea:\n",
    "- encapsulate a `Module` within a class\n",
    "- that know which entries need to be read and passed to the module\n",
    "- and then records the results with the assigned entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")\n",
    "# LazyLinear automatically fetches observation space\n",
    "module = torch.nn.LazyLinear(out_features=env.action_spec.shape[-1])\n",
    "policy = TensorDictModule(\n",
    "    module,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specialized wrapper\n",
    "`Actor` provides default values for the `in_keys` and `out_keys`, making integration with common environments straightforward.\n",
    "\n",
    "[List of specialized modules](https://pytorch.org/rl/stable/reference/modules.html#tdmodules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.modules import Actor\n",
    "\n",
    "module = torch.nn.LazyLinear(out_features=env.action_spec.shape[-1])\n",
    "\n",
    "# specialized actor policy\n",
    "policy = Actor(module)\n",
    "\n",
    "## non-specialized policy\n",
    "# policy = TensorDictModule(\n",
    "#     module,\n",
    "#     in_keys=[\"observation\"],\n",
    "#     out_keys=[\"action\"],\n",
    "# )\n",
    "\n",
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Networks\n",
    "Regular modules that can be used without recurring to tensordict features. Two most common are `MLP` and `ConvNet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.modules import MLP\n",
    "\n",
    "## TensorDictModule\n",
    "# module = torch.nn.LazyLinear(out_features=env.action_spec.shape[-1])\n",
    "\n",
    "# MLP module\n",
    "module = MLP(out_features=env.action_spec.shape[-1],\n",
    "             num_cells=[32, 64],\n",
    "             activation_class=torch.nn.Tanh,)\n",
    "\n",
    "policy = Actor(module)\n",
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "print(rollout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilistic Policies\n",
    "TorchRL facilitates stocastic policy by grouping operations like:\n",
    "- building distribution from parameters\n",
    "- sampling from that distribution\n",
    "- retrieving log-probability\n",
    "\n",
    "In the next example, we'll build an actor that relies on a regular normal distribution using three components:\n",
    "- an `MLP` backbone reading observation of size [3], and outputting a single tensor of size [2].\n",
    "- a `NormalParamExtractor` module that will split the output into two chunks - a mean and a std dev of size [1]\n",
    "- a `ProbabilisticActor` that will read those parameters as `in_keys`, create a distribution with them, and populate the tensordict with samples and log-probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        loc: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        sample_log_prob: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        scale: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunzid/anaconda3/lib/python3.12/site-packages/tensordict/nn/probabilistic.py:497: UserWarning: deterministic_sample wasn't found when queried on <class 'torch.distributions.normal.Normal'>. SafeProbabilisticModule is falling back on mean instead. For better code quality and efficiency, make sure to either provide a distribution with a deterministic_sample attribute or to change the InteractionMode to the desired value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch.distributions import Normal\n",
    "from torchrl.modules import ProbabilisticActor\n",
    "\n",
    "# out is 2 instead of 1\n",
    "backbone = MLP(in_features=3, out_features=2)\n",
    "# split the out of size [2] into a mean and std dev of size [1]\n",
    "extractor = NormalParamExtractor()\n",
    "module = torch.nn.Sequential(backbone, extractor)\n",
    "\n",
    "# instead of observation to action, we have observation > mean/std > action\n",
    "td_module = TensorDictModule(module,\n",
    "                             in_keys=[\"observation\"],\n",
    "                             out_keys=[\"loc\", \"scale\"])\n",
    "\n",
    "policy = ProbabilisticActor(td_module,\n",
    "                            in_keys=[\"loc\",\"scale\"],\n",
    "                            out_keys=[\"action\"],\n",
    "                            distribution_class=Normal,\n",
    "                            return_log_prob=True,)\n",
    "\n",
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling of action can chose expected value instead of using random samples with `set_exploration_type()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.utils import ExplorationType, set_exploration_type\n",
    "\n",
    "with set_exploration_type(ExplorationType.MEAN):\n",
    "    # takes the mean as action\n",
    "    rolloutMean = env.rollout(max_steps=10, policy=policy)\n",
    "\n",
    "with set_exploration_type(ExplorationType.RANDOM):\n",
    "    # takes the mean as action\n",
    "    rolloutDist = env.rollout(max_steps=10, policy=policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration\n",
    "Deterministic policies don't explore inherently. Torchrl has modules for exploration.\n",
    "\n",
    "Epsilon-greedy exploration module parameters:\n",
    "- epsilon: (1 is every action random, 0 is no exploration)\n",
    "- anneal: decrease epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.nn import TensorDictSequential\n",
    "from torchrl.modules import EGreedyModule\n",
    "\n",
    "# # MLP module\n",
    "# backbone = MLP(in_features=3, out_features=2,\n",
    "#              num_cells=[32, 64])\n",
    "# policy = Actor(module)\n",
    "\n",
    "policy = Actor(MLP(3, 1, num_cells=[32, 64]))\n",
    "\n",
    "exploration_module = EGreedyModule(\n",
    "    spec=   env.action_spec, annealing_num_steps=1000, eps_init=0.5\n",
    ")\n",
    "\n",
    "exploration_policy = TensorDictSequential(policy, exploration_module)\n",
    "\n",
    "with set_exploration_type(ExplorationType.MEAN):\n",
    "    # turns off exploration\n",
    "    rollout1 = env.rollout(max_steps=10, policy=exploration_policy)\n",
    "\n",
    "with set_exploration_type(ExplorationType.RANDOM):\n",
    "    # turns on exploration\n",
    "    rollout2 = env.rollout(max_steps=10, policy=exploration_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4319],\n",
      "         [ 1.6355]],\n",
      "\n",
      "        [[ 0.4239],\n",
      "         [ 0.1764]],\n",
      "\n",
      "        [[ 0.3959],\n",
      "         [-1.3561]],\n",
      "\n",
      "        [[ 0.3594],\n",
      "         [ 1.5796]],\n",
      "\n",
      "        [[ 0.3245],\n",
      "         [ 0.0813]],\n",
      "\n",
      "        [[ 0.2960],\n",
      "         [ 0.1487]],\n",
      "\n",
      "        [[ 0.2750],\n",
      "         [ 0.1530]],\n",
      "\n",
      "        [[ 0.2605],\n",
      "         [ 0.1623]],\n",
      "\n",
      "        [[ 0.2513],\n",
      "         [ 0.1778]],\n",
      "\n",
      "        [[ 0.2460],\n",
      "         [ 0.2005]]], grad_fn=<StackBackward0>) \n",
      "\n",
      "tensor([[[ -3.6267],\n",
      "         [ -5.7703]],\n",
      "\n",
      "        [[ -3.7987],\n",
      "         [ -6.3049]],\n",
      "\n",
      "        [[ -4.1803],\n",
      "         [ -6.9850]],\n",
      "\n",
      "        [[ -4.7753],\n",
      "         [ -7.6511]],\n",
      "\n",
      "        [[ -5.5833],\n",
      "         [ -8.6991]],\n",
      "\n",
      "        [[ -6.5935],\n",
      "         [ -9.7239]],\n",
      "\n",
      "        [[ -7.7793],\n",
      "         [-10.7903]],\n",
      "\n",
      "        [[ -9.0957],\n",
      "         [-10.0133]],\n",
      "\n",
      "        [[-10.4822],\n",
      "         [ -9.0440]],\n",
      "\n",
      "        [[-11.4969],\n",
      "         [ -8.1109]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack([rollout1[\"action\"], rollout2[\"action\"]], 1), '\\n')\n",
    "print(torch.stack([rollout1[\"next\", \"reward\"], rollout2[\"next\", \"reward\"]], 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Value actors\n",
    "Policy can be a composite module. **Q-Value actors** require an estimate of action value, and will greedily pick up the action with the highest value. DQN is for continuous state-space where a neural network encode the `Q(s,a)` value map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotDiscreteTensorSpec(\n",
      "    shape=torch.Size([2]),\n",
      "    space=DiscreteBox(n=2),\n",
      "    device=cpu,\n",
      "    dtype=torch.int64,\n",
      "    domain=discrete)\n"
     ]
    }
   ],
   "source": [
    "env = GymEnv(\"CartPole-v1\")\n",
    "print(env.action_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a value network that produces one value per action when it reads a state from the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        action_value: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        chosen_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.modules import QValueModule\n",
    "\n",
    "num_actions = 2\n",
    "value_net = TensorDictModule(\n",
    "    MLP(out_features=num_actions, num_cells=[32, 32]),\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action_value\"],\n",
    ")\n",
    "\n",
    "policy = TensorDictSequential(value_net, # writes \"action_value\"\n",
    "                              QValueModule(spec=env.action_spec), # reads \"action_value\" by default\n",
    "                              )\n",
    "\n",
    "rollout = env.rollout(max_steps=3, policy=policy)\n",
    "print(rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the output has \"action_values\" and \"chosen_action_values\". Since it relies on `argmax` (only exploitation), we will use `EGreedyModule` for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1172],\n",
      "         [-0.1195]],\n",
      "\n",
      "        [[-0.1217],\n",
      "         [-0.1240]],\n",
      "\n",
      "        [[-0.1268],\n",
      "         [-0.1290]]], grad_fn=<StackBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_explore = TensorDictSequential(policy,\n",
    "                                      EGreedyModule(env.action_spec))\n",
    "\n",
    "with set_exploration_type(ExplorationType.RANDOM):\n",
    "    rollout_explore = env.rollout(max_steps=3, policy=policy_explore)\n",
    "\n",
    "print(torch.stack([rollout[\"chosen_action_value\"], rollout_explore[\"chosen_action_value\"]], 1), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and optimization\n",
    "\n",
    "Typical training loop:\n",
    "```\n",
    ">>> for i in range(n_collections):\n",
    "...     data = get_next_batch(env, policy)\n",
    "...     for j in range(n_optim):\n",
    "...         loss = loss_fn(data)\n",
    "...         loss.backward()\n",
    "...         optim.step()\n",
    "```\n",
    "#### RL objective functions\n",
    "Off-policy DDPG: requires a deterministic map from the observation space to the action space, and a value network that predicts the value of a state-action pair. The DDPG loss attempts to find the policy parameters that output actions that maximize the value for a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")\n",
    "\n",
    "from torchrl.modules import Actor, MLP, ValueOperator\n",
    "from torchrl.objectives import DDPGLoss\n",
    "\n",
    "n_obs = env.observation_spec[\"observation\"].shape[-1]\n",
    "n_act = env.action_spec.shape[-1]\n",
    "\n",
    "actor = Actor(\n",
    "    MLP(in_features=n_obs,\n",
    "         out_features=n_act,\n",
    "           num_cells=[32, 32]))\n",
    "\n",
    "value_net = ValueOperator(\n",
    "    MLP(in_features=n_obs + n_act,\n",
    "         out_features=1,\n",
    "           num_cells=[32, 32]),\n",
    "    in_keys=[\"observation\", \"action\"],\n",
    ")\n",
    "\n",
    "ddpg_loss = DDPGLoss(actor_network=actor, value_network=value_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        loss_actor: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        loss_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        pred_value: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        pred_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        target_value: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        target_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        td_error: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False) \n",
      "\n",
      "53.0244026184082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunzid/anaconda3/lib/python3.12/site-packages/torchrl/objectives/common.py:29: UserWarning: No target network updater has been associated with this loss module, but target parameters have been found. While this is supported, it is expected that the target network updates will be manually performed. You can deactivate this warning by turning the RL_WARNINGS env variable to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(max_steps=100, policy=actor)\n",
    "loss_vals = ddpg_loss(rollout)\n",
    "print(loss_vals, '\\n')\n",
    "\n",
    "total_loss = 0\n",
    "for key, val in loss_vals.items():\n",
    "    if key.startswith(\"loss_\"):\n",
    "        total_loss += val\n",
    "    \n",
    "print(total_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a LossModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optim=Adam(ddpg_loss.parameters())\n",
    "total_loss.backward()\n",
    "\n",
    "# # with following items\n",
    "# optim.step()\n",
    "# optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target parameters\n",
    "Target parameters represent a delayed or smoothed version of the parameters over time. The value are updated by user's requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.objectives import SoftUpdate\n",
    "updater = SoftUpdate(ddpg_loss, eps=0.99)\n",
    "\n",
    "# updating\n",
    "updater.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection and storage\n",
    "#### Data collectors\n",
    "The primary data collector is the `SyncDataCollector` -\n",
    "- executing policy within the environment\n",
    "- resetting the environment when necessary\n",
    "- providing batches of a predefined size\n",
    "\n",
    "Collectors don't reset between consecutive batches, thus two batches can share a trajectory.\n",
    "\n",
    "Collector arguments\n",
    "- batch size (`frames_per_batch`)\n",
    "- length of iterator\n",
    "- the policy\n",
    "- the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.envs import GymEnv\n",
    "from torchrl.envs.utils import RandomPolicy\n",
    "\n",
    "env = GymEnv(\"CartPole-v1\")\n",
    "env.set_seed(0)\n",
    "\n",
    "policy = RandomPolicy(env.action_spec)\n",
    "collector = SyncDataCollector(env, policy, frames_per_batch=200, total_frames=-1) #-1 indicates never ending collector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([200]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([200, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([200]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([200, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([200]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "for data in collector:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(data[\"collector\", \"traj_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replay buffers\n",
    "To temporarily store data after collection.\n",
    "```\n",
    ">>> for data in collector:\n",
    "...     storage.store(data)\n",
    "...     for i in range(n_optim):\n",
    "...         sample = storage.sample()\n",
    "...         loss_val = loss_fn(sample)\n",
    "...         loss_val.backward()\n",
    "...         optim.step() # etc\n",
    "```\n",
    "`ReplayBuffer`: TorchRL data storage parent class. They are composable:\n",
    "- edit storage type\n",
    "- sampling technique\n",
    "- writing heuristic\n",
    "- transforms\n",
    "\n",
    "General requirement: type of storage.\n",
    "Recommendation: a `TensorStorage` subclass, like `LazyMemmapStorage`. It can be populated with `add()` (single element) or `extend()` (multiple element) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data.replay_buffers import LazyMemmapStorage, ReplayBuffer\n",
    "\n",
    "buffer = ReplayBuffer(storage=LazyMemmapStorage(max_size=1000))\n",
    "\n",
    "indices = buffer.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer has the same number of elements as from the collector\n",
    "assert len(buffer) == collector.frames_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([30, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        collector: TensorDict(\n",
      "            fields={\n",
      "                traj_ids: Tensor(shape=torch.Size([30]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([30]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([30]),\n",
      "            device=cpu,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([30]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "sample = buffer.sample(batch_size=30)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchRL's logging\n",
    "Logging is crucial for reporting results for the outside world, and for performance check. TorchRL has several loggers that interface with custom backends such as wandb, tensorboard, CSV logger. They require at least an experiment name, and directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.record import CSVLogger\n",
    "logger = CSVLogger(exp_name='my_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the logger is instantiated, logging method `log_scalar()` can be called in several places across the training example to log values such as reward, loss value, time elapsed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log_scalar(\"my_scalar\", 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording videos\n",
    "In `GymEnv`, `from_pixels=True` makes env `step` function write a `pixels` entry containing images of observation, and `pixels_only=False` will indicate you want the observations to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import GymEnv\n",
    "\n",
    "env = GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False)\n",
    "\n",
    "print(env.rollout(max_steps=3))\n",
    "\n",
    "from torchrl.envs import TransformedEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recorder and logger can be used to save video from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.record import VideoRecorder\n",
    "\n",
    "recorder = VideoRecorder(logger, tag=\"my_video\")\n",
    "record_env = TransformedEnv(env, recorder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = record_env.rollout(max_steps=3)\n",
    "# Uncomment this line to save the video on disk:\n",
    "# recorder.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunzid/anaconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "795726461"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import time\n",
    "\n",
    "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
    "\n",
    "env = TransformedEnv(GymEnv(\"CartPole-v1\"), StepCounter())\n",
    "env.set_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing a policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq\n",
    "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
    "\n",
    "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
    "value_net = Mod(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n",
    "\n",
    "policy = Seq(value_net, QValueModule(spec=env.action_spec))\n",
    "\n",
    "exploration_module = EGreedyModule(\n",
    "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5)\n",
    "\n",
    "policy_explore = Seq(policy, exploration_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data collection and replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
    "\n",
    "init_rand_steps = 5000\n",
    "frames_per_batch = 100\n",
    "optim_steps = 10\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=-1,\n",
    "    init_random_frames=init_rand_steps,\n",
    ")\n",
    "rb = ReplayBuffer(storage=LazyTensorStorage(100_000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss module and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torchrl.objectives import DQNLoss, SoftUpdate\n",
    "\n",
    "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
    "optim = Adam(loss.parameters(), lr=0.02)\n",
    "updater = SoftUpdate(loss, eps=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl._utils import logger as torchrl_logger\n",
    "from torchrl.record import CSVLogger, VideoRecorder\n",
    "\n",
    "path = \"./training_loop\"\n",
    "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
    "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
    "record_env = TransformedEnv(\n",
    "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 10:59:52,531 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,544 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,556 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,571 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,584 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,597 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,611 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,622 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,635 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,649 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
      "2024-10-14 10:59:52,758 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,770 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,785 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,799 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,816 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,830 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,843 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,858 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,871 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:52,889 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
      "2024-10-14 10:59:53,002 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,017 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,029 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,043 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,058 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,070 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,084 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,097 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,109 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,123 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
      "2024-10-14 10:59:53,240 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,254 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,266 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,280 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,293 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,306 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,321 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,334 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,351 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,365 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
      "2024-10-14 10:59:53,475 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,491 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,507 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,523 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,539 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,557 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,573 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,591 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,607 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,623 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
      "2024-10-14 10:59:53,736 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,756 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,779 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,796 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,812 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,832 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,849 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,865 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,881 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:53,897 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
      "2024-10-14 10:59:54,160 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,173 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,188 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,205 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,224 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,239 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,258 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,273 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,288 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,303 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
      "2024-10-14 10:59:54,436 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,451 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,464 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,480 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,497 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,515 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,530 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,547 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,562 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,575 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
      "2024-10-14 10:59:54,690 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,707 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,722 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,738 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,753 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,770 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,789 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,804 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,825 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:54,842 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
      "2024-10-14 10:59:55,268 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,286 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,300 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,315 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,329 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,343 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,358 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,375 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,393 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,408 [torchrl][INFO] Max num steps: 103, rb length 6200\n",
      "2024-10-14 10:59:55,518 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,534 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,549 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,565 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,583 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,596 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,611 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,627 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,643 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,659 [torchrl][INFO] Max num steps: 174, rb length 6300\n",
      "2024-10-14 10:59:55,783 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,796 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,810 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,821 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,835 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,851 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,870 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,884 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,896 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,907 [torchrl][INFO] Max num steps: 174, rb length 6400\n",
      "2024-10-14 10:59:55,983 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:55,996 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,010 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,031 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,050 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,066 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,084 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,099 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,113 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,132 [torchrl][INFO] Max num steps: 174, rb length 6500\n",
      "2024-10-14 10:59:56,274 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,294 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,314 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,330 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,345 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,361 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,378 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,391 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,407 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,430 [torchrl][INFO] Max num steps: 174, rb length 6600\n",
      "2024-10-14 10:59:56,551 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,564 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,577 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,593 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,605 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,618 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,631 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,642 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,659 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,673 [torchrl][INFO] Max num steps: 174, rb length 6700\n",
      "2024-10-14 10:59:56,746 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,755 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,767 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,778 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,792 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,803 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,814 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,824 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,834 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,846 [torchrl][INFO] Max num steps: 174, rb length 6800\n",
      "2024-10-14 10:59:56,901 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,909 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,918 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,927 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,936 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,946 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,956 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,967 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,977 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:56,987 [torchrl][INFO] Max num steps: 174, rb length 6900\n",
      "2024-10-14 10:59:57,047 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,056 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,067 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,078 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,087 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,098 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,108 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,119 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,130 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,140 [torchrl][INFO] Max num steps: 174, rb length 7000\n",
      "2024-10-14 10:59:57,314 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,323 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,333 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,343 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,354 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,363 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,375 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,386 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,397 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,409 [torchrl][INFO] Max num steps: 174, rb length 7200\n",
      "2024-10-14 10:59:57,469 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,479 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,491 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,501 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,512 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,524 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,534 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,546 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,557 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,568 [torchrl][INFO] Max num steps: 194, rb length 7300\n",
      "2024-10-14 10:59:57,635 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,644 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,653 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,663 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,673 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,686 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,695 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,707 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,717 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,728 [torchrl][INFO] Max num steps: 194, rb length 7400\n",
      "2024-10-14 10:59:57,783 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,791 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,801 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,812 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,822 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,833 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,846 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,857 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,870 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,881 [torchrl][INFO] Max num steps: 194, rb length 7500\n",
      "2024-10-14 10:59:57,942 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:57,951 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:57,962 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:57,972 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:57,982 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:57,994 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:58,005 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:58,015 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:58,026 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:58,036 [torchrl][INFO] Max num steps: 194, rb length 7600\n",
      "2024-10-14 10:59:58,097 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,106 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,115 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,132 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,144 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,156 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,166 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,178 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,191 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,202 [torchrl][INFO] Max num steps: 194, rb length 7700\n",
      "2024-10-14 10:59:58,260 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,269 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,277 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,286 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,298 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,307 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,318 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,329 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,339 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,349 [torchrl][INFO] Max num steps: 194, rb length 7800\n",
      "2024-10-14 10:59:58,404 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,415 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,426 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,437 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,451 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,465 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,481 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,496 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,508 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,527 [torchrl][INFO] Max num steps: 194, rb length 7900\n",
      "2024-10-14 10:59:58,640 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,654 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,668 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,680 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,694 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,709 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,722 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,736 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,748 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,759 [torchrl][INFO] Max num steps: 210, rb length 8000\n",
      "2024-10-14 10:59:58,760 [torchrl][INFO] solved after 30000 steps, 1270 episodes and in 9.330539226531982s.\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "total_episodes = 0\n",
    "t0 = time.time()\n",
    "for i, data in enumerate(collector):\n",
    "    # Write data in replay buffer\n",
    "    rb.extend(data)\n",
    "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
    "    if len(rb) > init_rand_steps:\n",
    "        # Optim loop (we do several optim steps\n",
    "        # per batch collected for efficiency)\n",
    "        for _ in range(optim_steps):\n",
    "            sample = rb.sample(128)\n",
    "            loss_vals = loss(sample)\n",
    "            loss_vals[\"loss\"].backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            # Update exploration factor\n",
    "            exploration_module.step(data.numel())\n",
    "            # Update target params\n",
    "            updater.step()\n",
    "            if i % 10:\n",
    "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
    "            total_count += data.numel()\n",
    "            total_episodes += data[\"next\", \"done\"].sum()\n",
    "    if max_length > 200:\n",
    "        break\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "torchrl_logger.info(\n",
    "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_env.rollout(max_steps=1000, policy=policy)\n",
    "video_recorder.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pendulum: writing own environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n",
    "DEFAULT_X = np.pi\n",
    "DEFAULT_Y = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 things to take care of when designing a new environment class:\n",
    "* `EnvBase._reset()`, resetting the simulator at a (potentially random) initial state;\n",
    "* `EnvBase._step()` which codes for the state transition dynamic;\n",
    "* `EnvBase._set_seed()` which implements seeding mechanism;\n",
    "* the environment specs\n",
    "\n",
    "For the pendulum task, we need\n",
    "- a motion equation (following action)\n",
    "- a reward equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coding the effect of an action: `_step()`\n",
    "The _step() method should do the following:\n",
    "\n",
    "- Read the input keys (such as \"action\") and execute the simulation based on these;\n",
    "- Retrieve observations, done state and reward;\n",
    "- Write the set of observation values along with the reward and done state at the corresponding entries in a new TensorDict.\n",
    "- Merge the output TensorDict (as \"next\" key) in the input TensorDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _step(tensordict):\n",
    "    th, thdot = tensordict[\"th\"], tensordict[\"thdot\"]  # th := theta\n",
    "\n",
    "    g_force = tensordict[\"params\", \"g\"]\n",
    "    mass = tensordict[\"params\", \"m\"]\n",
    "    length = tensordict[\"params\", \"l\"]\n",
    "    dt = tensordict[\"params\", \"dt\"]\n",
    "    u = tensordict[\"action\"].squeeze(-1)\n",
    "    u = u.clamp(-tensordict[\"params\", \"max_torque\"], tensordict[\"params\", \"max_torque\"])\n",
    "    costs = angle_normalize(th) ** 2 + 0.1 * thdot**2 + 0.001 * (u**2)\n",
    "\n",
    "    new_thdot = (\n",
    "        thdot\n",
    "        + (3 * g_force / (2 * length) * th.sin() + 3.0 / (mass * length**2) * u) * dt\n",
    "    )\n",
    "    new_thdot = new_thdot.clamp(\n",
    "        -tensordict[\"params\", \"max_speed\"], tensordict[\"params\", \"max_speed\"]\n",
    "    )\n",
    "    new_th = th + new_thdot * dt\n",
    "    reward = -costs.view(*tensordict.shape, 1)\n",
    "    done = torch.zeros_like(reward, dtype=torch.bool)\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"th\": new_th,\n",
    "            \"thdot\": new_thdot,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "            \"reward\": reward,\n",
    "            \"done\": done,\n",
    "        },\n",
    "        tensordict.shape,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def angle_normalize(x):\n",
    "    return ((x + torch.pi) % (2 * torch.pi)) - torch.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resetting the simulator: `_reset()`\n",
    "\n",
    "- _reset() writes observation entries and a done (default=False) state.\n",
    "- expects (not mandatory) a tensordict as input (beneficial in multi-agent settings)    # since the environment is stateless, we expect the previous output as input.\n",
    "    # For this, ``EnvBase`` expects some state_spec to be available\n",
    "    self.state_spec = self.observation_spec.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset(self, tensordict):\n",
    "    if tensordict is None or tensordict.is_empty():\n",
    "        # if no ``tensordict`` is passed, we generate a single set of hyperparameters\n",
    "        # Otherwise, we assume that the input ``tensordict`` contains all the relevant\n",
    "        # parameters to get started.\n",
    "        tensordict = self.gen_params(batch_size=self.batch_size)\n",
    "\n",
    "    high_th = torch.tensor(DEFAULT_X, device=self.device)\n",
    "    high_thdot = torch.tensor(DEFAULT_Y, device=self.device)\n",
    "    low_th = -high_th\n",
    "    low_thdot = -high_thdot\n",
    "\n",
    "    # for non batch-locked environments, the input ``tensordict`` shape dictates the number\n",
    "    # of simulators run simultaneously. In other contexts, the initial\n",
    "    # random state's shape will depend upon the environment batch-size instead.\n",
    "    th = (\n",
    "        torch.rand(tensordict.shape, generator=self.rng, device=self.device)\n",
    "        * (high_th - low_th)\n",
    "        + low_th\n",
    "    )\n",
    "    thdot = (\n",
    "        torch.rand(tensordict.shape, generator=self.rng, device=self.device)\n",
    "        * (high_thdot - low_thdot)\n",
    "        + low_thdot\n",
    "    )\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"th\": th,\n",
    "            \"thdot\": thdot,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "        },\n",
    "        batch_size=tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment metadata: `env.*_spec`\n",
    "\n",
    "The specs define the input and output domain of the environment. They can also be used to instantiate lazily defined neural networks and test scripts. There are four specs that we must code in our environment:\n",
    "\n",
    "- `EnvBase.observation_spec`: This will be a `CompositeSpec` instance where each key is an observation (a CompositeSpec can be viewed as a dictionary of specs).\n",
    "- `EnvBase.action_spec`: It can be any type of spec, it corresponds to the \"action\" entry in the input tensordict;\n",
    "- `EnvBase.reward_spec`: provides information about the reward space;\n",
    "- `EnvBase.done_spec`: provides information about the space of the done flag.\n",
    "\n",
    "TorchRL specs are organized in two general containers:\n",
    "- input_spec which contains the specs of the information that the step function reads (divided between action_spec containing the action and state_spec containing all the rest),\n",
    "- output_spec which encodes the specs that the step outputs (observation_spec, reward_spec and done_spec).\n",
    "\n",
    "In general, you should not interact directly with output_spec and input_spec but only with their content: observation_spec, reward_spec, done_spec, action_spec and state_spec. TorchRL offers multiple TensorSpec subclasses to encode the environment’s input and output characteristics.\n",
    "\n",
    "##### Specs shape\n",
    "The environment specs leading dimensions must match the environment batch-size. This is done to enforce that every component of an environment (including its transforms) have an accurate representation of the expected input and output shapes. This is something that should be accurately coded in stateful settings. For non batch-locked environments, such as the one in our example (see below), this is irrelevant as the environment batch size will most likely be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_spec(self, td_params):\n",
    "    # Under the hood, this will populate self.output_spec[\"observation\"]\n",
    "    self.observation_spec = CompositeSpec(\n",
    "        th=BoundedTensorSpec(\n",
    "            low=-torch.pi,\n",
    "            high=torch.pi,\n",
    "            shape=(),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        thdot=BoundedTensorSpec(\n",
    "            low=-td_params[\"params\", \"max_speed\"],\n",
    "            high=td_params[\"params\", \"max_speed\"],\n",
    "            shape=(),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        # we need to add the ``params`` to the observation specs, as we want\n",
    "        # to pass it at each step during a rollout\n",
    "        params=make_composite_from_td(td_params[\"params\"]),\n",
    "        shape=(),\n",
    "    )\n",
    "    # since the environment is stateless, we expect the previous output as input.\n",
    "    # For this, ``EnvBase`` expects some state_spec to be available\n",
    "    self.state_spec = self.observation_spec.clone()\n",
    "    # action-spec will be automatically wrapped in input_spec when\n",
    "    # `self.action_spec = spec` will be called supported\n",
    "    self.action_spec = BoundedTensorSpec(\n",
    "        low=-td_params[\"params\", \"max_torque\"],\n",
    "        high=td_params[\"params\", \"max_torque\"],\n",
    "        shape=(1,),\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))\n",
    "\n",
    "\n",
    "def make_composite_from_td(td):\n",
    "    # custom function to convert a ``tensordict`` in a similar spec structure\n",
    "    # of unbounded values.\n",
    "    composite = CompositeSpec(\n",
    "        {\n",
    "            key: make_composite_from_td(tensor)\n",
    "            if isinstance(tensor, TensorDictBase)\n",
    "            else UnboundedContinuousTensorSpec(\n",
    "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
    "            )\n",
    "            for key, tensor in td.items()\n",
    "        },\n",
    "        shape=td.shape,\n",
    "    )\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducible experiments: seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_seed(self, seed: Optional[int]):\n",
    "    rng = torch.manual_seed(seed)\n",
    "    self.rng = rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `EnvBase` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_params(g=10.0, batch_size=None) -> TensorDictBase:\n",
    "    \"\"\"Returns a ``tensordict`` containing the physical parameters such as gravitational force and torque or speed limits.\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = []\n",
    "    td = TensorDict(\n",
    "        {\n",
    "            \"params\": TensorDict(\n",
    "                {\n",
    "                    \"max_speed\": 8,\n",
    "                    \"max_torque\": 2.0,\n",
    "                    \"dt\": 0.05,\n",
    "                    \"g\": g,\n",
    "                    \"m\": 1.0,\n",
    "                    \"l\": 1.0,\n",
    "                },\n",
    "                [],\n",
    "            )\n",
    "        },\n",
    "        [],\n",
    "    )\n",
    "    if batch_size:\n",
    "        td = td.expand(batch_size).contiguous()\n",
    "    return td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the environment as non-batch_locked by turning the homonymous attribute to False. This means that we will not enforce the input tensordict to have a batch-size that matches the one of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PendulumEnv(EnvBase):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "    batch_locked = False\n",
    "\n",
    "    def __init__(self, td_params=None, seed=None, device=\"cpu\"):\n",
    "        if td_params is None:\n",
    "            td_params = self.gen_params()\n",
    "\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        self._make_spec(td_params)\n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    # Helpers: _make_step and gen_params\n",
    "    gen_params = staticmethod(gen_params)\n",
    "    _make_spec = _make_spec\n",
    "\n",
    "    # Mandatory methods: _step, _reset and _set_seed\n",
    "    _reset = _reset\n",
    "    _step = staticmethod(_step)\n",
    "    _set_seed = _set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing environment\n",
    "TorchRL provides a simple function `check_env_specs()` to check that a (transformed) environment has an input/output structure that matches the one dictated by its specs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 18:07:52,320 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "env = PendulumEnv()\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at our specs to have a visual representation of the environment signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    th: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    thdot: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_speed: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        max_torque: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        g: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        m: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        l: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([])),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]))\n",
      "state_spec: CompositeSpec(\n",
      "    th: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    thdot: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_speed: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        max_torque: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        g: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        m: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        l: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([])),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"state_spec:\", env.state_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute a couple of commands too to check that the output structure matches what is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset tensordict TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                g: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                l: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                m: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_speed: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_torque: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        th: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thdot: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.reset()\n",
    "print(\"reset tensordict\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the env.rand_step() to generate an action randomly from the action_spec domain. A tensordict containing the hyperparameters and the current state must be passed since our environment is stateless. In stateful contexts, env.rand_step() works perfectly too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random step tensordict TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        g: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        l: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        m: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_speed: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        max_torque: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                th: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thdot: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                g: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                l: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                m: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_speed: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_torque: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        th: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thdot: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.rand_step(td)\n",
    "print(\"random step tensordict\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming an environment\n",
    "\n",
    "Writing environment transforms for stateless simulators is slightly more complicated than for stateful ones: transforming an output entry that needs to be read at the following iteration requires to apply the inverse transform before calling meth.step() at the next step. This is an ideal scenario to showcase all the features of TorchRL’s transforms!\n",
    "\n",
    "For instance, in the following transformed environment we unsqueeze the entries [\"th\", \"thdot\"] to be able to stack them along the last dimension. We also pass them as in_keys_inv to squeeze them back to their original shape once they are passed as input in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunzid/anaconda3/lib/python3.12/site-packages/torchrl/envs/transforms/transforms.py:2164: UserWarning: The `unsqueeze_dim` kwarg will be removed in v0.6. Please use `dim` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = TransformedEnv(\n",
    "    env,\n",
    "    # ``Unsqueeze`` the observations that we will concatenate\n",
    "    UnsqueezeTransform(\n",
    "        unsqueeze_dim=-1,\n",
    "        in_keys=[\"th\", \"thdot\"],\n",
    "        in_keys_inv=[\"th\", \"thdot\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing custom transforms\n",
    "TorchRL’s transforms may not cover all the operations one wants to execute after an environment has been executed. Writing a transform does not require much effort. As for the environment design, there are two steps in writing a transform:\n",
    "\n",
    "- Getting the dynamics right (forward and inverse);\n",
    "- Adapting the environment specs.\n",
    "\n",
    "A transform can be used in two settings: on its own, it can be used as a `Module`. It can also be used appended to a `TransformedEnv`. The structure of the class allows to customize the behavior in the different contexts.\n",
    "\n",
    "A `Transform` skeleton can be summarized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(nn.Module):\n",
    "    def forward(self, tensordict):\n",
    "        ...\n",
    "    def _apply_transform(self, tensordict):\n",
    "        ...\n",
    "    def _step(self, tensordict):\n",
    "        ...\n",
    "    def _call(self, tensordict):\n",
    "        ...\n",
    "    def inv(self, tensordict):\n",
    "        ...\n",
    "    def _inv_apply_transform(self, tensordict):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three entry points (`forward()`, `_step()` and `inv()`) which all receive `tensordict.TensorDict` instances. The first two will eventually go through the keys indicated by in_keys and call `_apply_transform()` to each of these. The results will be written in the entries pointed by `Transform.out_keys` if provided (if not the `in_keys` will be updated with the transformed values). If inverse transforms need to be executed, a similar data flow will be executed but with the `Transform.inv()` and `Transform._inv_apply_transform()` methods and across the `in_keys_inv` and `out_keys_inv` list of keys. The following figure summarized this flow for environments and replay buffers.\n",
    "\n",
    "In some cases, a transform will not work on a subset of keys in a unitary manner, but will execute some operation on the parent environment or work with the entire input tensordict. In those cases, the `_call()` and `forward()` methods should be re-written, and the `_apply_transform()` method can be skipped.\n",
    "\n",
    "Let us code new transforms that will compute the sine and cosine values of the position angle, as these values are more useful to us to learn a policy than the raw angle value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinTransform(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.sin()\n",
    "\n",
    "    # The transform must also modify the data at reset time\n",
    "    def _reset(\n",
    "        self, tensordict: TensorDictBase, tensordict_reset: TensorDictBase\n",
    "    ) -> TensorDictBase:\n",
    "        return self._call(tensordict_reset)\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "class CosTransform(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.cos()\n",
    "\n",
    "    # The transform must also modify the data at reset time\n",
    "    def _reset(\n",
    "        self, tensordict: TensorDictBase, tensordict_reset: TensorDictBase\n",
    "    ) -> TensorDictBase:\n",
    "        return self._call(tensordict_reset)\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "t_sin = SinTransform(in_keys=[\"th\"], out_keys=[\"sin\"])\n",
    "t_cos = CosTransform(in_keys=[\"th\"], out_keys=[\"cos\"])\n",
    "env.append_transform(t_sin)\n",
    "env.append_transform(t_cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenates the observations onto an “observation” entry. `del_keys=False` ensures that we keep these values for the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transform = CatTensors(\n",
    "    in_keys=[\"sin\", \"cos\", \"thdot\"], dim=-1, out_key=\"observation\", del_keys=False\n",
    ")\n",
    "env.append_transform(cat_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, let us check that our environment specs match what is received:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executing a rollout\n",
    "Executing a rollout is a succession of simple steps:\n",
    "- reset the environment\n",
    "- while some condition is not met:\n",
    "    - compute an action given a policy\n",
    "    - execute a step given this action\n",
    "    - collect the data\n",
    "    - make a MDP step\n",
    "- gather the data and return\n",
    "\n",
    "These operations have been conveniently wrapped in the `rollout()` method, from which we provide a simplified version here below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from rollout: TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        dt: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        g: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        l: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        m: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_speed: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        max_torque: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([100]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                th: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thdot: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([100]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                dt: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                g: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                l: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                m: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_speed: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_torque: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([100]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        th: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thdot: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([100]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "def simple_rollout(steps=100):\n",
    "    # preallocate:\n",
    "    data = TensorDict({}, [steps])\n",
    "    # reset\n",
    "    _data = env.reset()\n",
    "    for i in range(steps):\n",
    "        _data[\"action\"] = env.action_spec.rand()\n",
    "        _data = env.step(_data)\n",
    "        data[i] = _data\n",
    "        _data = step_mdp(_data, keep_other=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"data from rollout:\", simple_rollout(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching computations\n",
    "\n",
    "The last unexplored end of our tutorial is the ability that we have to batch computations in TorchRL. Because our environment does not make any assumptions regarding the input data shape, we can seamlessly execute it over batches of data. Even better: for non-batch-locked environments such as our Pendulum, we can change the batch size on the fly without recreating the environment. To do this, we just generate parameters with the desired shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                g: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                l: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                m: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_speed: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_torque: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([1]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        th: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thdot: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([1]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "rand step (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        g: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        l: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        m: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_speed: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        max_torque: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                th: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thdot: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([1]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                g: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                l: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                m: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_speed: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_torque: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([1]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        th: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thdot: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([1]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1  # number of environments to be executed in batch\n",
    "td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "print(\"reset (batch size of 10)\", td)\n",
    "td = env.rand_step(td)\n",
    "print(\"rand step (batch size of 10)\", td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing a rollout with a batch of data requires us to reset the environment out of the rollout function, since we need to define the batch_size dynamically and this is not supported by `rollout()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = env.rollout(\n",
    "    3,\n",
    "    auto_reset=False,  # we're executing the reset out of the ``rollout`` call\n",
    "    tensordict=env.reset(env.gen_params(batch_size=[batch_size])),\n",
    ")\n",
    "print(\"rollout of len 3 (batch size of 10):\", rollout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a simple policy\n",
    "In this example, we will train a simple policy using the reward as a differentiable objective, such as a negative loss. We will take advantage of the fact that our dynamic system is fully differentiable to backpropagate through the trajectory return and adjust the weights of our policy to maximize this value directly. Of course, in many settings many of the assumptions we make do not hold, such as differentiable system and full access to the underlying mechanics.%0A%0AStill, this is a very simple example that showcases how a training loop can be coded with a custom environment in TorchRL.%0A%0ALet us first write the policy network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "env.set_seed(0)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(1),\n",
    ")\n",
    "policy = TensorDictModule(\n",
    "    net,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(policy.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop\n",
    "We will successively:\n",
    "\n",
    "- generate a trajectory\n",
    "- sum the rewards\n",
    "- backpropagate through the graph defined by these operations\n",
    "- clip the gradient norm and make an optimization step\n",
    "- repeat\n",
    "\n",
    "At the end of the training loop, we should have a final reward close to 0 which demonstrates that the pendulum is upward and still as desired.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "pbar = tqdm.tqdm(range(20_000 // batch_size))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, 20_000)\n",
    "logs = defaultdict(list)\n",
    "\n",
    "for _ in pbar:\n",
    "    init_td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "    rollout = env.rollout(100, policy, tensordict=init_td, auto_reset=False)\n",
    "    traj_return = rollout[\"next\", \"reward\"].mean()\n",
    "    (-traj_return).backward()\n",
    "    gn = torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    pbar.set_description(\n",
    "        f\"reward: {traj_return: 4.4f}, \"\n",
    "        f\"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}\"\n",
    "    )\n",
    "    logs[\"return\"].append(traj_return.item())\n",
    "    logs[\"last_reward\"].append(rollout[..., -1][\"next\", \"reward\"].mean().item())\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def plot():\n",
    "    import matplotlib\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    is_ipython = \"inline\" in matplotlib.get_backend()\n",
    "    if is_ipython:\n",
    "        from IPython import display\n",
    "\n",
    "    with plt.ion():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(logs[\"return\"])\n",
    "        plt.title(\"returns\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(logs[\"last_reward\"])\n",
    "        plt.title(\"last reward\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        if is_ipython:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we have learned how to code a stateless environment from scratch. We touched the subjects of:\n",
    "\n",
    "The four essential components that need to be taken care of when coding an environment (step, reset, seeding and building specs). We saw how these methods and classes interact with the TensorDict class;\n",
    "\n",
    "How to test that an environment is properly coded using check_env_specs();\n",
    "\n",
    "How to append transforms in the context of stateless environments and how to write custom transformations;\n",
    "\n",
    "How to train a policy on a fully differentiable simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.data import OneHotDiscreteTensorSpec, DiscreteTensorSpec, BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([6]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MiniEnv(EnvBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # e.g. a conveyor belt with some values there\n",
    "        observation_spec = DiscreteTensorSpec(n=3, shape=torch.Size([6]))\n",
    "        self.observation_spec = CompositeSpec(\n",
    "            # observation=observation_spec, shape=observation_spec.shape\n",
    "            # observation=observation_spec, shape=[]\n",
    "            observation=observation_spec, shape=()\n",
    "        )\n",
    "        self.action_spec = OneHotDiscreteTensorSpec(\n",
    "            2,  # shift left or right\n",
    "            shape=torch.Size([2]),\n",
    "        )\n",
    "        self.reward_spec = UnboundedContinuousTensorSpec(shape=torch.Size([1]))\n",
    "\n",
    "    def _reset(self, tensordict, *kwargs):\n",
    "        pass\n",
    "\n",
    "    def _step(self, tensordict):\n",
    "        pass\n",
    "\n",
    "    def _set_seed(self, seed):\n",
    "        pass\n",
    "\n",
    "env = MiniEnv()\n",
    "env.fake_tensordict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
